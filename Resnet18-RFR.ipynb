{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENClgf6TbE8_"
      },
      "outputs": [],
      "source": [
        "from typing import NewType\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from torch.utils.data.sampler import SubsetRandomSampler as Subset\n",
        "from copy import deepcopy\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_yWTBefhKaR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuBPJzowFPvm"
      },
      "outputs": [],
      "source": [
        "# seed 고정\n",
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLZf0d9WbE9B"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "momemtum = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQEJ0Cr3bE9B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import tifffile as tiff\n",
        "import numpy as np\n",
        "\n",
        "# Load the CSV file\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/pro626/train/train_data.csv')\n",
        "\n",
        "# Assuming the TIFF files are named with their patient ID and stored in 'images/' directory\n",
        "def load_tiff_images_to_tensor(num_patients, num_channels=52, image_size=(150, 150)):\n",
        "    # Initialize a tensor to hold the image data\n",
        "    images_tensor = torch.zeros((num_patients, num_channels, *image_size))\n",
        "\n",
        "    for patient_id in range(1, num_patients + 1):  # Assuming IDs start from 1 to 225\n",
        "        image_path = f'/content/drive/MyDrive/pro626/train/images/{patient_id}.tiff'\n",
        "        image_data = tiff.imread(image_path)  # This loads the multi-channel image\n",
        "        image_tensor = torch.from_numpy(image_data).float()\n",
        "        images_tensor[patient_id - 1] = image_tensor\n",
        "\n",
        "    return images_tensor\n",
        "\n",
        "# Load images into a tensor\n",
        "num_patients = 225  # Total number of patients\n",
        "images_tensor = load_tiff_images_to_tensor(num_patients)\n",
        "\n",
        "# Check if the tensor dimensions match your expectation\n",
        "print(images_tensor.shape)  # Should print torch.Size([225, 52, 150, 150])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngpS7V3ZgsOK"
      },
      "outputs": [],
      "source": [
        "images_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACqTU7uU8yAk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjMTD4MY8pr3"
      },
      "source": [
        "### Gaussian Blur\n",
        "##### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YER-KFQR8nIx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class GaussianBlur(nn.Module):\n",
        "    def __init__(self, kernel_size, sigma, in_channels):\n",
        "        super(GaussianBlur, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.sigma = sigma\n",
        "        self.in_channels = in_channels\n",
        "        self.padding = kernel_size // 2\n",
        "        self.kernel = self.create_kernel(kernel_size, sigma, in_channels)\n",
        "\n",
        "    def create_kernel(self, kernel_size, sigma, in_channels):\n",
        "        # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
        "        x_coord = torch.arange(kernel_size)\n",
        "        x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
        "        y_grid = x_grid.t()\n",
        "        xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
        "\n",
        "        mean = (kernel_size - 1) / 2.\n",
        "        variance = sigma ** 2.\n",
        "\n",
        "        # Calculate the 2-dimensional gaussian kernel\n",
        "        gaussian_kernel = (1. / (2. * math.pi * variance)) * \\\n",
        "                          torch.exp(\n",
        "                              -torch.sum((xy_grid - mean) ** 2., dim=-1) / \\\n",
        "                              (2 * variance)\n",
        "                          )\n",
        "        # Make sure sum of values in gaussian kernel equals 1.\n",
        "        gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
        "\n",
        "        # Reshape to 2d depthwise convolutional weight\n",
        "        gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
        "        gaussian_kernel = gaussian_kernel.repeat(in_channels, 1, 1, 1)\n",
        "\n",
        "        gaussian_filter = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size,\n",
        "                                    groups=in_channels, bias=False, padding=self.padding)\n",
        "\n",
        "        gaussian_filter.weight.data = gaussian_kernel\n",
        "        gaussian_filter.weight.requires_grad = False\n",
        "\n",
        "        return gaussian_filter\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.kernel(x)\n",
        "\n",
        "# 이미지 텐서에 가우시안 블러 적용\n",
        "# 여기서 images_tensor_normalized는 (N, C, H, W)의 형태를 가진 텐서이고, C는 채널 수입니다.\n",
        "gaussian_blur = GaussianBlur(kernel_size=5, sigma=1.0, in_channels=52)\n",
        "# images_tensor_blurred = gaussian_blur(images_tensor_normalized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIcruGfr8-9-"
      },
      "outputs": [],
      "source": [
        "images_tensor_blurred = gaussian_blur(images_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxxhlQr5bE9C"
      },
      "outputs": [],
      "source": [
        "# Convert survival times into a tensor\n",
        "survival_times = torch.tensor(labels_df['OSmonth'].values).float()\n",
        "\n",
        "# Each image tensor at index i corresponds to the survival time at index i in survival_times\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9gOg3G8bE9C"
      },
      "source": [
        "# Normalizaiton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUJf0lqEbE9D"
      },
      "outputs": [],
      "source": [
        "# Normalize the images tensor to have mean=0 and std=1\n",
        "# Calculate the mean and std if not already known. Here, assuming the need to calculate:\n",
        "mean = images_tensor.mean()\n",
        "std = images_tensor.std()\n",
        "\n",
        "# Normalize\n",
        "images_tensor_normalized = (images_tensor - mean) / std\n",
        "\n",
        "print(f\"Mean: {images_tensor.mean()}, Std: {images_tensor.std()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niM9jrV4bE9D"
      },
      "source": [
        "# Splitting the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YVPDtlBbE9D"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# Create a dataset from tensors\n",
        "full_dataset = TensorDataset(images_tensor_normalized, survival_times)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CQLhoWKbE9E"
      },
      "source": [
        "# Data Loading and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-EH81o5gsON"
      },
      "outputs": [],
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErVVkN2doYmL"
      },
      "source": [
        "원래꺼\n",
        "\n",
        "MSE: 1306.7742668761416\n",
        "\n",
        "MAE: 30.26724149007083\n",
        "\n",
        "R^2: 0.0696811053030808"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItMGwIp8gsON"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImageRegressionCNN(nn.Module):\n",
        "    def __init__(self, reduction = 16):\n",
        "        super(ImageRegressionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)  # 입력 채널 3 (RGB), 출력 채널 16\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.se = SEBlock(16, reduction=16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2) # 출력 채널 32\n",
        "        self.fc1 = nn.Linear(32 * 37 * 37, 1024)  # 예시: 이미지 크기가 224x224이고, 두 번의 풀링을 거쳤을 경우\n",
        "        self.fc2 = nn.Linear(1024, 128)  # 최종 출력: 예측 값 1개\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.se(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # 회귀 문제이므로 마지막에 활성화 함수 사용하지 않음\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOPNA0sDsh7p"
      },
      "source": [
        "새로운것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Ursi7iEtk8"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# 데이터 증강을 위한 변환 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # 수평 반전\n",
        "    transforms.RandomRotation(15),  # 최대 15도 회전\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 최대 10% 이동\n",
        "    transforms.RandomApply([transforms.GaussianBlur(3)]),  # 확률적으로 가우시안 블러 적용\n",
        "])\n",
        "\n",
        "# CustomDataset은 앞서 설명한 CustomDataset 클래스와 동일하며, transform 파라미터를 포함합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpUXiGEdgsON"
      },
      "outputs": [],
      "source": [
        "full_dataset_size = len(full_dataset)\n",
        "test_size = 0\n",
        "train_val_size = full_dataset_size - test_size\n",
        "# Splitting the dataset into training+validation and test\n",
        "\n",
        "train_val_dataset, test_dataset = random_split(full_dataset, [train_val_size, test_size])\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Size of training+validation set: {len(train_val_dataset)}\")\n",
        "print(f\"Size of test set: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrahR9QkLPMd"
      },
      "outputs": [],
      "source": [
        "class SingleChannelDataset(Dataset):\n",
        "    def __init__(self, full_dataset, channel_index, transform=None, indices=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            full_dataset (Dataset): The complete dataset containing both images_tensor and labels.\n",
        "            channel_index (int): The index of the channel to use.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            indices (list of int, optional): List of indices to use from the full_dataset.\n",
        "        \"\"\"\n",
        "        self.full_dataset = full_dataset\n",
        "        self.channel_index = channel_index\n",
        "        self.transform = transform\n",
        "        self.indices = indices if indices is not None else range(len(full_dataset))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        actual_idx = self.indices[idx]\n",
        "        image, label = self.full_dataset[actual_idx]\n",
        "        # Select the specific channel\n",
        "        image = image[self.channel_index, :, :].unsqueeze(0)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJw44AYCXTIr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class FeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        # ResNet18의 avgpool과 fc 레이어 이전의 특징을 추출\n",
        "        self.features = torch.nn.Sequential(*list(pretrained_model.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)  # Flatten the features\n",
        "        return x\n",
        "\n",
        "def extract_channel_features(dataset, num_channels):\n",
        "    # 사전 학습된 resnet18 모델 불러오기\n",
        "    pretrained_model = models.resnet18(pretrained=True)\n",
        "    feature_extractor = FeatureExtractor(pretrained_model)\n",
        "    feature_extractor.eval()  # 평가 모드로 설정\n",
        "\n",
        "    # GPU 사용 설정 (가능한 경우)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    feature_extractor.to(device)\n",
        "\n",
        "    extracted_features = []\n",
        "    for channel_index in range(num_channels):\n",
        "        channel_dataset = SingleChannelDataset(\n",
        "            full_dataset=dataset,\n",
        "            channel_index=channel_index,\n",
        "            transform=None\n",
        "        )\n",
        "\n",
        "        data_loader = DataLoader(channel_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        channel_features = []\n",
        "        channel_labels = []  # 채널별 레이블 수집을 위한 리스트\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in data_loader:\n",
        "                inputs = inputs.repeat(1, 3, 1, 1)\n",
        "                inputs = inputs.to(device)\n",
        "                features = feature_extractor(inputs)\n",
        "                channel_features.append(features.cpu().numpy())\n",
        "                channel_labels.extend(labels.cpu().numpy())  # 수정된 부분: 레이블 저장\n",
        "\n",
        "        # 현재 채널의 특징을 전체 리스트에 추가\n",
        "        extracted_features.append(np.concatenate(channel_features, axis=0))\n",
        "\n",
        "    # 수정된 부분: 모든 채널을 처리한 후에 레이블 리스트를 반환\n",
        "    return np.concatenate(extracted_features, axis=1), np.array(channel_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XNrBlX0gsOO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 이미지 데이터셋과 레이블이 준비되어 있다고 가정\n",
        "# images_tensor: 전체 이미지 데이터 (N, C, H, W)\n",
        "# survival_times: 각 이미지에 대한 레이블 (N,)\n",
        "\n",
        "num_channels = 52  # 총 채널 수\n",
        "\n",
        "extracted_features, extracted_labels = extract_channel_features(dataset=train_val_dataset, num_channels=52)\n",
        "print(type(extracted_features))\n",
        "print(len(extracted_features))\n",
        "if len(extracted_features) > 0:\n",
        "    print(type(extracted_features[0]))\n",
        "    print(np.array(extracted_features[0]).shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    extracted_features,  # 이미지로부터 추출된 특징 행렬을 직접 사용\n",
        "    extracted_labels,    # 각 이미지 또는 데이터 포인트에 대응하는 레이블 또는 타겟 값\n",
        "    test_size=0.2,       # 예: 테스트 데이터셋의 비율을 20%로 설정\n",
        "    random_state=42      # 결과의 재현성을 위한 랜덤 시드 설정\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s88wzeokTiMg"
      },
      "outputs": [],
      "source": [
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150, 200],  # 트리의 수\n",
        "#     'max_depth': [None, 10, 20, 30],  # 트리의 최대 깊이\n",
        "#     'min_samples_split': [2, 5, 10],  # 분할을 위한 최소 샘플 수\n",
        "#     'min_samples_leaf': [1, 2, 4],  # 리프 노드의 최소 샘플 수\n",
        "#     'max_features': ['auto', 'sqrt']  # 각 분할에서 고려할 특성의 최대 수\n",
        "# }\n",
        "param_grid = {\n",
        "    'n_estimators': [100],  # 트리의 수\n",
        "    'max_depth': [30],  # 트리의 최대 깊이\n",
        "    'min_samples_split': [5],  # 분할을 위한 최소 샘플 수\n",
        "    'min_samples_leaf':  [4],  # 리프 노드의 최소 샘플 수\n",
        "    'max_features': ['auto']  # 각 분할에서 고려할 특성의 최대 수\n",
        "}\n",
        "# MSE를 스코어링 함수로 사용\n",
        "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# GridSearchCV 객체 생성\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring=mse_scorer, n_jobs=-1, verbose=2)\n",
        "\n",
        "# 그리드 서치 수행 - ensemble_features와 ensemble_labels을 사용\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적의 모델로 테스트 데이터에 대한 예측 수행\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "print(\"shape of ensemble_features:\", extracted_features.shape)\n",
        "print(\"shape of ensemble_labels:\", extracted_labels.shape)\n",
        "\n",
        "predicted_labels = best_rf.predict(X_test)\n",
        "\n",
        "# 성능 지표 계산\n",
        "mse = mean_squared_error(y_test, predicted_labels)\n",
        "mae = mean_absolute_error(y_test, predicted_labels)\n",
        "r2 = r2_score(y_test, predicted_labels)\n",
        "\n",
        "print(y_test)\n",
        "print(predicted_labels)\n",
        "\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test R^2: {r2:.4f}\")\n",
        "\n",
        "# # Optionally, evaluate the ensemble model\n",
        "# test_datasets = [SingleChannelDataset(test_dataset, i) for i in range(num_channels)]\n",
        "# # 각 채널별로 DataLoader 생성\n",
        "# test_loaders = [DataLoader(dataset, batch_size=8, shuffle=False) for dataset in test_datasets]\n",
        "\n",
        "# # 각 채널에 대한 예측을 수집합니다.\n",
        "# test_features = []\n",
        "# all_test_labels = []   # 실제 레이블은 한 번만 저장하기 위한 변수\n",
        "\n",
        "# for channel_index, loader in enumerate(test_loaders):\n",
        "#     # 채널별 모델을 불러옵니다.\n",
        "#    # 채널별 모델 인스턴스를 생성합니다.\n",
        "#     model = ImageRegressionCNN()  # 또는 적절한 모델 클래스 사용\n",
        "#     # 저장된 모델 상태를 불러와 모델 인스턴스에 적용합니다.\n",
        "#     model.load_state_dict(best_models_per_channel[channel_index])\n",
        "#     # 모델을 계산 장치에 할당합니다.\n",
        "#     model = model.to(device)\n",
        "#     model.eval()\n",
        "\n",
        "#     channel_predictions = []\n",
        "#     channel_predictions = []\n",
        "#     with torch.no_grad():\n",
        "#         for images, labels in loader:\n",
        "#             images = images.to(device)\n",
        "#             output = model(images)\n",
        "#             channel_predictions.append(output.cpu().numpy())\n",
        "#             if channel_index == 0:  # Collect labels only once (assuming labels are same for all channels)\n",
        "#                 all_test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "#         # 채널별 예측값을 수집합니다.\n",
        "#     test_features.append(np.concatenate(channel_predictions, axis=0))\n",
        "\n",
        "\n",
        "# # 모든 채널의 예측값을 가로로 결합하여 하나의 특성 벡터로 만듭니다.\n",
        "# all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "\n",
        "# # 예측값을 가로로 결합하여 최종 특성 행렬을 구성합니다.\n",
        "# test_features = np.hstack(test_features)\n",
        "\n",
        "# print(test_features.shape)\n",
        "# print(all_test_labels.shape)\n",
        "# # assert test_features.shape[0] == all_test_labels.shape[0], \"Mismatch in the number of labels and predictions.\"\n",
        "\n",
        "\n",
        "\n",
        "# # RandomForestRegressor로 최종 예측 및 평가\n",
        "# # predicted_labels = rf.predict(test_features)\n",
        "# predicted_labels = best_rf.predict(test_features)\n",
        "# print(\"all_test_labels\", all_test_labels)\n",
        "# print(\"predicted_labels\", predicted_labels)\n",
        "\n",
        "# print(\"MSE:\", mean_squared_error(all_test_labels, predicted_labels))\n",
        "# print(\"MAE:\", mean_absolute_error(all_test_labels, predicted_labels))\n",
        "# print(\"R^2:\", r2_score(all_test_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuyVTxxpa1XC"
      },
      "outputs": [],
      "source": [
        "print(y_test)\n",
        "print(predicted_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}